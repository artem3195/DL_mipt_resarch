{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33b473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eed2428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "869b0b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = \" \"\n",
    "end_token = \".\"\n",
    "\n",
    "def read_names(path_to_file):\n",
    "    global start_token\n",
    "    \n",
    "    with open(path_to_file) as f:\n",
    "        names = f.read()[:-1].split('\\n')\n",
    "        #names = [start_token + line for line in names]\n",
    "        names = [f'{start_token}{line}{end_token}' for line in names]\n",
    "        return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b274211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘names’ already there; not retrieving.\n",
      "File ‘names_ru’ already there; not retrieving.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    names = read_names('../datasets/names_dataset/names')\n",
    "except FileNotFoundError:\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/names_dataset/names -nc -O names\n",
    "    names = read_names('./names')\n",
    "    \n",
    "try:\n",
    "    names_ru = read_names('../datasets/names_dataset/names_ru')\n",
    "except FileNotFoundError:\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/names_dataset/names_ru -nc -O names_ru\n",
    "    names_ru = read_names('./names_ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea69231",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n samples =  7944\n",
      " Abagael.  Абагаел.\n",
      " Claresta.  Слареста.\n",
      " Glory.  Глорй.\n",
      " Liliane.  Лилиане.\n",
      " Prissie.  Приссие.\n",
      " Geeta.  Геета.\n",
      " Giovanne.  Гиованне.\n",
      " Piggy.  Пиггй.\n"
     ]
    }
   ],
   "source": [
    "print ('n samples = ',len(names_ru))\n",
    "for idx in np.arange(0, len(names), 1000):\n",
    "    print(names[idx], names_ru[idx])\n",
    "\n",
    "assert len(names) == len(names_ru), 'Wrong lengths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b0bc427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length = 17\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length =\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)),bins=25, label='en');\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names_ru)),bins=25, alpha=0.3, label='ru');\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faaa9076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tokens = 56\n"
     ]
    }
   ],
   "source": [
    "all_tokens_set_en = set()\n",
    "for name in names:\n",
    "    all_tokens_set_en.update(set(name))\n",
    "\n",
    "tokens_en = list(all_tokens_set_en)# <list of all unique characters in the dataset>\n",
    "\n",
    "num_tokens_en = len(tokens_en)\n",
    "print (f'num_tokens = {num_tokens_en}')\n",
    "\n",
    "assert 50 < num_tokens_en < 60, \"Names should contain within 50 and 60 unique tokens depending on encoding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7491d877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tokens = 55\n"
     ]
    }
   ],
   "source": [
    "all_tokens_set_ru = set()\n",
    "for name in names_ru:\n",
    "    all_tokens_set_ru.update(set(name))\n",
    "\n",
    "tokens_ru = list(all_tokens_set_ru)# <list of all unique characters in the dataset>\n",
    "\n",
    "num_tokens_ru = len(tokens_ru)\n",
    "print (f'num_tokens = {num_tokens_ru}')\n",
    "\n",
    "assert 50 < num_tokens_ru < 60, \"Names should contain within 50 and 60 unique tokens depending on encoding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d102d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_id_en = {\n",
    "    token: idx for idx, token in enumerate(tokens_en)\n",
    "}\n",
    "\n",
    "token_to_id_ru = {\n",
    "    token: idx for idx, token in enumerate(tokens_ru)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80e344db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems alright!\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens_ru) == len(token_to_id_ru), \"dictionaries must have same size\"\n",
    "\n",
    "for i in range(num_tokens_ru):\n",
    "    assert token_to_id_ru[tokens_ru[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "for i in range(num_tokens_en):\n",
    "    assert token_to_id_en[tokens_en[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "    \n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ceb1bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(names, token_to_id, max_len=None, pad=None, dtype='int32', batch_first=False):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    pad = token_to_id[' ']\n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        line_ix = [token_to_id[c] for c in names[i]]\n",
    "        names_ix[i, :len(line_ix)] = line_ix\n",
    "        \n",
    "    if not batch_first: # convert [batch, time] into [time, batch]\n",
    "        names_ix = np.transpose(names_ix)\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0915a60b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22 22 22]\n",
      " [25 25 25]\n",
      " [ 3  3  3]\n",
      " [36 36  3]\n",
      " [28 28  6]\n",
      " [36 36 54]\n",
      " [ 6  4 22]\n",
      " [47 47 22]\n",
      " [54 54 22]] \n",
      " (9, 3)\n"
     ]
    }
   ],
   "source": [
    "example = to_matrix(names[:3], token_to_id_en)\n",
    "print(example,'\\n', example.shape)\n",
    "del example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c41a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15dc431",
   "metadata": {},
   "source": [
    "# Teacher forcing model with LSTM and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "342974ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_tokens, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_tokens = num_tokens\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_tokens, emb_dim)# <YOUR CODE HERE>\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=emb_dim, hidden_size= hid_dim,\n",
    "                           num_layers = n_layers, dropout = dropout) # <YOUR CODE HERE>\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout) # <YOUR CODE HERE>\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        \n",
    "        # Compute an embedding from the src data and apply dropout to it\n",
    "        # <YOUR CODE HERE>\n",
    "        \n",
    "        #embedded = [src sent len, batch size, emb dim]\n",
    "        embedded = self.embedding(src) \n",
    "        \n",
    "        embedded = self.dropout(embedded) \n",
    "        \n",
    "        # Compute the RNN output values of the encoder RNN. \n",
    "        # outputs, hidden and cell should be initialized here. Refer to nn.LSTM docs ;)\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded) # <YOUR CODE HERE> \n",
    "        \n",
    "        #outputs = [src sent len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        # Note: hidden - hidden state from the last state for each batch\n",
    "        # element \n",
    "        shp = [self.n_layers, src.shape[1], self.hid_dim]\n",
    "        assert list(hidden.size()) == shp, 'Wrong hidden dim'\n",
    "        assert list(cell.size()) == shp, 'Wrong cell dim'\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "086f2644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 32])\n",
      "torch.Size([2, 32, 128]) torch.Size([2, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "# check encoder forward pass:\n",
    "t = to_matrix(sample(names, 32), token_to_id_en, max_len=MAX_LENGTH)\n",
    "t = torch.LongTensor(t)\n",
    "print(t.shape) \n",
    "\n",
    "tencoder = Encoder(\n",
    "    num_tokens = len(token_to_id_en),\n",
    "    emb_dim = 64, hid_dim = 128,\n",
    "    n_layers = 2, dropout = 0.5)\n",
    "\n",
    "tenc_h, tenc_c  = tencoder.forward(t)\n",
    "\n",
    "print(tenc_h.size(), tenc_c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d0a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666f00a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92cbce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_tokens, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.num_tokens = num_tokens\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_tokens, emb_dim)# <YOUR CODE HERE>\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=emb_dim, hidden_size= hid_dim,\n",
    "                           num_layers = n_layers, dropout= dropout) # <YOUR CODE HERE>\n",
    "        \n",
    "        # Note:\n",
    "        # aditional linear layer to convert rnn outputputs hid_dim to \n",
    "        # probs of tokens dim - voc size\n",
    "        self.out = nn.Linear(hid_dim, num_tokens) # <YOUR CODE HERE>\n",
    "         \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, trg, hidden, cell):\n",
    "        \n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        # add first dim = 1: \n",
    "        #trg = trg.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        # Compute an embedding from the input data and apply dropout to it\n",
    "        embedded = self.embedding(trg) # <YOUR CODE HERE>\n",
    "        embedded = self.dropout(embedded)\n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        \n",
    "        # Compute the RNN output values of the encoder RNN. \n",
    "        # outputs, hidden and cell should be initialized here. Refer to nn.LSTM docs ;)\n",
    "\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))# <YOUR CODE HERE>\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #sent len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        prediction = self.out(output)\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        # Note: we do not need softmax because we will predict\n",
    "        # the most likely token using argmax\n",
    "        \n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c5e1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3e69f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 32])\n",
      "torch.Size([17, 32, 55]) torch.Size([2, 32, 128]) torch.Size([2, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "# check forward pass of decoder\n",
    "# we take slice of batch because will use teacher forcing\n",
    "\n",
    "t = to_matrix(sample(names_ru, 32), token_to_id_ru, max_len=MAX_LENGTH)\n",
    "t = torch.LongTensor(t)#[0,:]\n",
    "print(t.shape) \n",
    "\n",
    "tdecoder = Decoder(\n",
    "    num_tokens = len(token_to_id_ru),\n",
    "    emb_dim = 64, hid_dim = 128,\n",
    "    n_layers = 2, dropout = 0.5\n",
    ")\n",
    "\n",
    "tdec_res = tdecoder.forward(t, tenc_h, tenc_c)\n",
    "print(tdec_res[0].size(), tdec_res[1].size(), tdec_res[2].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d764a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb9184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccb84f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        #trg = [trg sent len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "    \n",
    "        \n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        outputs, _, _ = self.decoder(trg, hidden, cell)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f4c8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b154c9af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "torch.Size([17, 32]) torch.Size([17, 32])\n",
      "torch.Size([17, 32, 55])\n",
      "torch.Size([17, 32])\n"
     ]
    }
   ],
   "source": [
    "# check Seq2Seq\n",
    "\n",
    "#tencoder = Encoder()\n",
    "#tdecoder = Decoder()\n",
    "\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'device: {device}')\n",
    "\n",
    "tmodel = Seq2Seq(tencoder, tdecoder, device)\n",
    "\n",
    "t_src = to_matrix(sample(names, 32), token_to_id_en, max_len=MAX_LENGTH)\n",
    "t_src = torch.LongTensor(t_src)\n",
    "\n",
    "t_trg = to_matrix(sample(names_ru, 32), token_to_id_ru, max_len=MAX_LENGTH)\n",
    "t_trg = torch.LongTensor(t_trg)\n",
    "\n",
    "print(t_src.size(), t_trg.size())\n",
    "\n",
    "res_tseq2seq = tmodel.forward(\n",
    "    t_src, \n",
    "    t_trg\n",
    ")\n",
    "\n",
    "print(res_tseq2seq.size())\n",
    "\n",
    "preds = res_tseq2seq.argmax(-1)\n",
    "print(preds.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca7612c",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c791e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions: \n",
    "\n",
    "def init_weights(m):\n",
    "    # <YOUR CODE HERE>\n",
    "    for p in m.parameters():\n",
    "        nn.init.uniform_(p, -0.08, 0.08)\n",
    "        \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18dd3b0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 818,871 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/artem/Documents/ML_projets/venvs/work_env/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# train parameters: \n",
    "\n",
    "n_epoch = 5\n",
    "batch_size = 128\n",
    "emb_size_ = 128\n",
    "rnn_num_units_ = 256 \n",
    "n_layers_ = 1\n",
    "dropout_ = 0.5\n",
    "\n",
    "enc = Encoder(\n",
    "    num_tokens = len(token_to_id_en),\n",
    "    emb_dim = emb_size_, hid_dim = rnn_num_units_,\n",
    "    n_layers = n_layers_, dropout = dropout_)\n",
    "\n",
    "dec = Decoder(\n",
    "    num_tokens = len(token_to_id_ru),\n",
    "    emb_dim = emb_size_, hid_dim = rnn_num_units_,\n",
    "    n_layers = n_layers_, dropout = dropout_)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "# initialize model\n",
    "model.apply(init_weights)\n",
    "\n",
    "PAD_IDX = token_to_id_ru[' ']\n",
    "#criterion = nn.NLLLoss(ignore_index= PAD_IDX)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "opt = optim.Adam(model.parameters())\n",
    "\n",
    "loss_li = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c50a94c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 5/5..\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEXCAYAAABPkyhHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyU0lEQVR4nO3dd3yV5dnA8d+Vkz1IIAkrYe8dMDIERK1WQBStWlGLs1X7Wtu6au2y9fWttba0Dtx71L3AiSLIFAibAIGwE0bCyiCQeb1/nAcaIONAcnLOybm+n8/55Dz7enLgXLnHc9+iqhhjjAluIb4OwBhjjO9ZMjDGGGPJwBhjjCUDY4wxWDIwxhiDJQNjjDFYMjDGYyLycxHZIyLFIpLYhNf9nYi80FTXM8HJkoEJOCJyjYhkOF/Ku0TkCxEZ1cBzbhWR8+vYHgZMAX6oqrGquq8h16vjOueISE71dar6V1X9qTeuZ8xRlgxMQBGRu4B/A38F2gAdgaeAiV6+dBsgEsj08nWM8QlLBiZgiEg88CBwu6p+qKqHVLVcVaer6r3OPhEi8m8R2em8/i0iEc62JBH5VEQOish+EZkrIiEi8jrupDLdKW385oTr9gSynMWDIvKtiHQWERWR0Gr7zRaRnzrvbxCReSLyDxE5ICJbRGRctX1bicjLTowHRORjEYkBvgDaO3EUi0h7EfmziLxR7dhLRCTTuY/ZItKn2ratInKPiKwSkQIReUdEIhv3kzDNkSUDE0hG4P7r/KM69vk9MBxIAwYBQ4E/ONvuBnKAZNx/6f8OUFWdDGwHLnaqgP5e/YSqugHo5ywmqOp5HsY7DHcSSQL+DrwoIuJsex2Ids7bGviXqh4CxgE7nThiVXVn9RM6iekt4NfOfXyOO4mFV9vtx8BYoAswELih2vEHG1qlZponSwYmkCQCe1W1oo59rgUeVNU8Vc0H/gJMdraVA+2ATk6JYq56d3Cubar6vKpWAq86124jIu1wf+nfpqoHnFi+8/CcVwGfqerXqloO/AOIAs6qts/jqrpTVfcD03EnRgBUNUFV5zX81kxzY8nABJJ9QFL1qpkatAe2VVve5qwDeBTIBmaIyGYR+a13wjxm99E3qlrivI0FOgD7VfXAaZzzuPtT1SpgB5BS03WBEueaxtTJkoEJJAuBUuDSOvbZCXSqttzRWYeqFqnq3araFbgEuEtEfuDsd6olhEPOz+hq69p6eOwOoJWIJNSwrb44jrs/p9qpA5Dr4bWNqZElAxMwVLUA+BMwVUQuFZFoEQkTkXEicrSe/y3gDyKSLCJJzv5vAIjIBBHp7nyBFgCVQJVz3B6g6ynEko/7C/gnIuISkZuAbh4euwt3Q/FTItLSuYezq8WR6DSW1+Rd4CIR+YHT3fVu3AlygaexG1MTSwYmoKjqP4G7cDcK5+P+K/sXwMfOLg8BGcAqYDWwzFkH0AP4BijGXcp4SlVnOdsexp1EDorIPR6G8zPgXtzVV/04tS/kybjbMNYDebgbhFHV9bgT2mYnlvbVD1LVLOAnwBPAXuBi3A3fZZ5c1OmhNPoU4jRBQmxyG2OMMVYyMMYYY8nAGGOMJQNjjDFYMjDGGAPU9fCO30pKStLOnTv7OgxjjAkoS5cu3auqyTVtC8hk0LlzZzIyMnwdhjHGBBQR2VbbNqsmMsYYY8nAGGOMJQNjjDFYMjDGGIMlA2OMMVgyMMYYgyUDY4wxBFky2LCniBfmbsZGajXGmOMFVTJYtGU/D322jp0FR3wdijHG+JWgSgZ92sYBsG5noY8jMcYY/xJUyaB3uxYArN9tycAYY6oLqmQQGxFKx1bRrNtV5OtQjDHGrwRVMgDo3TaOdVYyMMaY4wRdMujTrgVb9x7icFmlr0Mxxhi/EYTJII4qdXczNcYY4xaEycDdiLxul1UVGWPMUUGXDDq0jCYm3GXJwBhjqgm6ZBASIvRqG8e63VZNZIwxRwVdMgB3VdG6XYU2LIUxxjiCNhkUHalg674SfvP+SsY9NpeKyipfh2WMMT4T6usAfKFPO/ewFNc8/z27nHGKVuYc5IxOrXwZljHG+ExQlgx6tXX3KNp3qIz/vbQ/IQLfbdjr46iMMcZ3vJoMRKSDiMwSkbUikikiv6phn3NEpEBEVjivP3kzJnAPS/Hvq9J479YRTB7eiYGpCczdmO/tyxpjjN/ydjVRBXC3qi4TkThgqYh8raprT9hvrqpO8HIsx7l0cMqx92f3TObJbzdSUFJOfHRYU4ZhjDF+waslA1XdparLnPdFwDogpe6jmt6YnklUKczLtqoiY0xwarI2AxHpDAwGFtWweYSIrBSRL0SkX1PFdNSg1ATiIkOZs8GqiowxwalJehOJSCzwAfBrVT3x0d9lQCdVLRaR8cDHQI8aznELcAtAx44dGzW+UFcIo7onMWdjPqqKiDTq+Y0xxt95vWQgImG4E8GbqvrhidtVtVBVi533nwNhIpJUw37PqWq6qqYnJyc3epyjeySzq+AIm/KLG/3cxhjj77zdm0iAF4F1qjqlln3aOvshIkOdmPZ5M66anN3TnX+si6kxJhh5u2QwEpgMnFet6+h4EblNRG5z9rkCWCMiK4HHgUnqg3EiUltG0zUphvnWiGyMCUJebTNQ1XlAnRXwqvok8KQ34/DUyO5JfLAsh/LKKsJcQfk8njEmSNk3XjUjuydRUlbJ8u0HfR2KMcY0KUsG1YzolkiI2PMGxpjgY8mgmvioMAamJli7gTEm6FgyOMGo7kms2HGQwiPlvg7FGGOajCWDE4zsnkRllbJo835fh2KMMU3GksEJhnRKICrMdVxV0eGySv7w8Woe/nydDyMzxhjvCcrJbeoSEepiaJdWfLwil9SWUQzvmsi9769i3a5CROAnwzvRoVW0r8M0xphGZSWDGvxmbC96tI7loc/WMeGJeeQeKOGRywcQIsIbi7b5OjxjjGl0VjKoQb/28bx321ms3VnIdxvyuWhAOzomRjNrfT7vLtnBnef3JDLM5eswjTGm0VjJoA5927fg5+d0o2Oiu1po8ohOHCgp57NVu3wcmTHGNC5LBqfgrG6JdEuO4bWFW8krPMLy7QfIKzzi67CMMabBrJroFIgIk4d34s/T1zL0rzMBCHeFcGV6KreN6UZqyyibC8EYE5AsGZyiSUM7UlJeSVxkGG1bRDI7K493M3bw5qLthLtCaBkTxh3n9eAnwzv5OlRjjPGY+GC06AZLT0/XjIwMX4dxzM6Dh/ls1S72HiplRuYeBJh59xgrJRhj/IqILFXV9Jq2WcmgEbRPiOJnZ3cFIDUhij9+ksmm/GK6t47zcWTGGOMZa0BuZBf0bQvAV5l7fByJMcZ4zpJBI2sbH8mgDgnMyNzt61CMMcZjlgy84Id927Ayp4BdBYd9HYoxxnjEkoEXXNjPXVX09VqrKjLGBAZLBl7QvXUsXZNjmHFCu4GqUlUVeL23jDHNn/Um8pIL+7Xlme82ccXTCxjeNZHdhUeYn72XUJcw+55zcYVYt1NjjP+wZOAlt5/bHZcIc7P38tTsbFpEhZHaMoo1uYVs2XuI7q1jfR2iMcYcY8nAS2IjQrnnwl7cc2EvSsoqiAh1sTGviLH/nsua3AJLBsYYv2JtBk0gOjwUV4jQPTmWyLAQVucW+DokY4w5jiWDJhTqCqFPuxaWDIwxfseSQRPr3z6etTsLrVeRMcavWDJoYgNS4ikurWDLvkO+DsUYY46xZNDE+qfEA7DGqoqMMX7EkkET69EmlvDQEFbnWDIwxviPeruWikgkMAEYDbQHDgNrgM9UNbOeYzsArwFtAAWeU9XHTthHgMeA8UAJcIOqLjv1WwkMYSc0IpdWVHKotJJWMeE+jswYE8zqLBmIyF+A+cAIYBHwLPAuUAH8TUS+FpGBdZyiArhbVfsCw4HbRaTvCfuMA3o4r1uAp0/nRgLJgJQWrN1ZyL7iUiY+OZ+Ln5hnDcrGGJ+qr2SwWFUfqGXbFBFpDXSs7WBV3QXsct4Xicg6IAVYW223icBr6p5y7XsRSRCRds6xzdKAlHje+H47P3p6Adv2lQCQubOQAanxPo7MGBOs6iwZqOpn9WzPU1WP5p8Ukc7AYNwljOpSgB3VlnOcdScef4uIZIhIRn5+vieX9FtHG5F3HTzCP68chAjMzsrzcVTGmGBWXzXRv52f00Vk2okvTy8iIrHAB8CvVbXwdAJV1edUNV1V05OTk0/nFH6jV5s4Lh7UnmcmD+HyM1IZmBLP7A2BneCMMYGtvmqi152f/zjdC4hIGO5E8KaqfljDLrlAh2rLqc66ZivUFcITVw8+tjymZzJPzsrmYEkZCdHWkGyMaXr1VRMtdX5+V9Pr6H4i8kFNxzs9hV4E1qnqlFouMw24TtyGAwXNub2gJmN6taZKYe7Gvb4OxRgTpBpr1NKutawfCUwGVovICmfd73AanVX1GeBz3N1Ks3F3Lb2xkWIKGGkdEkiIDmN2Vj4XD2rv63CMMUGosZJBjf0iVXUeUOcsLk4votsbKY6A5AoRRvdI5rsN+VRVKSE28Y0xponZE8h+YkzPZPYWl5K587Ta140xpkEaKxnYn7INdG6vZKLCXEydle3rUIwxQajeZCAiLhF5s57d7mukeIJWYmwEt5/bjS8zdzPPGpKNMU2s3mSgqpVAJxGptc+jqs5o1KiC1E9Hd6Vjq2j+Mj2T8soqX4djjAkinlYTbQbmi8gfReSuoy9vBhaMIsNc/HFCXzbmFfPawm2+DscYE0Q8TQabgE+d/eOqvUwjO79Pa0b3SOKpWdkcKa/0dTjGmCDhUddSVf0LHBtWAlUt9mZQwUxEuG1MN659YRHTV+7kyvQO9R9kjDEN5FHJQET6i8hyIBPIFJGlItLPu6EFr7O6JdKrTRwvz9+K+zEMY4zxLk+riZ4D7lLVTqraCbgbeN57YQU3EeGGkZ1Zu6uQxVv2H7dtb3Ep7yzZToU1MBtjGpGnySBGVWcdXVDV2UCMVyIyAFyalkJCdBgvz996bN3ugiP8+NmF3PfBar5Ys9t3wRljmh2PexM5PYk6O68/4O5hZLwkKtzFpDM7MmPtbh7+Yh1frN7Fj59dSF5hKa3jInj9e+ttZIxpPJ6OTXQT8BfgQ9zjEM111hkvunlUF1bnHuSleVsor1TiIkN5/eahLN6yn4e/WE/W7iJ6tbVOXcaYhqs3GYiIC/hQVc9tgnhMNclxEbz50+EcLqtkxY6DdEqMpn1CFJ0SY/jn1xt44/tt/O+l/X0dpjGmGfD0CeQqEbEJen0kKtzFiG6JtE+IAqBVTDgTBrbjw2U5FJdW+Dg6Y0xz4GmbQTHuOQleFJHHj768GZip2+ThnThUVsn7GTvq39kYY+rhaZvBh87L+Im0DgkM7dKKR77M4oxOrRiQagU3Y8zpk/oeanLaDL7xpzaD9PR0zcjI8HUYPpdXdITLpi6grLKKj28fSYpTjWSMMTURkaWqml7TNmszCGCt4yJ5+cYzOVJWyQ0vLSY7r8jXIRljApS1GQS4nm3ieHbyGeQXlzLusblMmZFlA9wZY06Zp8ngQ+CPwBxgabWX8QNndU/im7vGMGFgex7/Npu731vZKGMaHSqt4O3F26mssvGRjGnu6mxAFpEWqlqoqq/WsK2j98IypyopNoJ/XZVG99axPPpVFuf1as3lZ6TWe5yqUlmlhLpO/rvgvYwd/Hn6WpLjIvhBnzbeCNsY4yfqKxnMPvpGRGaesO3jxg7GNNxtY7oxtHMrHpiWybZ9h1iQvZcHPlnDc3M2kbW76LgSQ+GRci5/egFXPruwxr/+52XvA+DTVbuaLH5jjG/U17W0+kT3rerYZvyEK0SYctUgxv17LudP+Y7ySiUiNITSiir++vl6uibH8NuxvRnRLZHrX1rM8u0HAfh4ee5xJYmKyiq+37wPEZiRuZsj5ZVEhrl8dFfGGG+rLxloLe9rWjZ+IrVlNFOuSuPdjB1MGNiOC/u1Zf+hMr7bkM8Lczdzy+tLiY8Ko7i0gmd+MoSpszbxzxlZXDSw3bEv/JU5BRSXVnDtsI68uWg7s9bnMW5AOx/fmTHGW+pLBq2duY6l2nuc5WSvRmYa5IK+bbig73/r+dsnRHH10I5ccUYqby/ezmsLt/HXywYwtn87WkSFcc3zi3h1wVZuHdMNgAXZexGBOy/oyVeZe5i+aqclA2OasfqSwfP8d67j6u8BXvBKRMarwlwhTB7RmckjOh9bd1a3JM7tlczUWdlcmd6BVjHhzMveS7/2LUiKjeCiAW15e8kOiksriI0IRVURsVpCY5qTOpPB0bmPTfP323F9mPDEXH77wSr+dVUay7Yf4KZRXQC4eFB7Xl24jTv+s4wdBw5zsKSMb+4aQ0J0uI+jNsY0ljp7E4nIH0SkZR3bzxORCY0flmlqvdrGcd/Y3sxYu4e7311JeaUyslsSAEM6tqRrUgwLNu2jVUw4e4vLmL5yp48jNsY0pvqqiVYDn4rIEWAZkA9EAj2ANOAb4K+1HSwiLwETgDxVPWngfRE5B/gE2OKs+lBVHzylOzCN5qaRXZi7cS9fZu4m3BXCmZ3dHchCQoTPfjkaEYgIDWHcY3N5f1nucVVNxpjAVmfJQFU/UdWRwG1AJuACCoE3gKGqeqeq5tdxileAsfXEMFdV05yXJQIfCgkR/vnjQSTHRTCsayuiwv/blTQq3EVkmAsR4fIhqazccZDsvGIfRmuMaUweDWGtqhuBjad6clWdIyKdT/U44ztJsRF8escoQkNqbyCeOLg9f/tyPR8sy+G+sb2bMDpjjLd4NDaRiKSLyEciskxEVh19NVIMI0RkpYh8ISL96ojhFhHJEJGM/Py6CiOmodq0iCQxNqLW7a3jIjm7RxIfLcu1cYuMaSY8ndzmTeBe3G0IVY14/WVAJ1UtFpHxuIe46FHTjqr6HPAcuOczaMQYzGm4/IxUfvGf5Tw2cyPdW8fSNSmG/ik2yrkxgcrTZJCvqtMa++KqWljt/eci8pSIJKnq3sa+lmlc5/dpQ+u4CB6f6a49FIGHLxvApKE2fqExgcjTZPCAiLwAzARKj65U1QZNhSkibYE9qqoiMhR3tdW+hpzTNI3IMBdzfnMu+w6VUVJawf99vo7ffriakrLKY88nGGMCh6fJ4EagNxDGf6uJlHrmRRaRt4BzgCQRyQEecM6Bqj4DXAH8XEQqgMPAJG2MgfhNk4gMcx2bavO5yen86u3lPPjpWjbmFXHf2N72UJoxAaTeOZABRCRLVXs1QTwesTmQ/VNFZRWPfpXFC/O2kBAVxmWDU9hdeIS8wlIeuqw/PdvE1X8SY4zXNGgOZMcCEenbiDGZZijUFcL94/sw/Rej6JwUw8sLtrI6t4CVOQd5bs5mX4dnjKmDp9VEw4EVIrIFd5uBAKqqA70WmQlYfdu34IOfn0VlleIKEe7/cBUfLc/lTxf3pUVkmK/DM8bUwNOSwVjcXT5/CFyMe4iJi70VlGkeXM6Da5PO7MiR8io+WWHjGRnjrzxNBlrLy5h6DUyNp0+7Fry9eLuvQzHG1MLTZPAZ8KnzcyawGfjCW0GZ5kVEuHpoBzJ3FrI6p8DX4RhjauBRMlDVAao60PnZAxgKLPRuaKY5mZiWQmRYCK8t3OrrUIwxNfC0ZHAcVV0GDGvkWEwzFh8VxqQzO/Le0hymzMhCVamqUuZuzCdrd5GvwzMm6HnUm6ja3MfgTiBDAGsNNKfkjxP6criskse/zWZT/iE27CliY14xyXERfHPnGOKjraeRMb7iackgrtorAnfbwURvBWWaJ1eI8LfLB3Dr2V35bPUuXCHCfWN7s/9QGX/7cp2vwzMmqHk6n8GxuZCdaTAP2rAR5nSICPeP78PkEZ1ISYhCRDhQUsZzczYzMS2F4V0TfR2iMUGpvjmQ/yQivZ33ESLyLbAJ2CMi5zdFgKZ5Sm0ZjYj7OYQ7z+9Jx1bR3P/hakorKn0cmTHBqb5qoquALOf99c7+ycAY6pj72JhTERXu4k8T+rJl7yFmrsvzdTjGBKX6kkFZteqgC4G3VLVSVdfh+VAWxtTr3N6taR0XwUfLc30dijFBqb5kUCoi/UUkGTgXmFFtW7T3wjLBxhUiTExrz+ysPA4cKvN1OMYEnfqSwa+A94H1wL9UdQuAM0Xlci/HZoLMpYNTKK9UPlu9y9ehGBN06kwGqrpIVXuraqKq/m+19Z+r6tXeD88Ek77tWtCzTSwfW1WRMU3utJ5ANsYbRISJaSlkbDvAjv0lvg7HmKBiycD4lYlp7QF45Mv17Ck84uNojAke1iPI+JXUltHcPKoLL8/fwleZuzm3V2siwlxUVlVx86gunNGpla9DNKZZqrdkICIPOT8f9H44xrjHMJp1zzlcPbQj63cXkZlbwLfr83jmO5s60xhv8aRksEREpgJfeTsYY47qlBjDgxP7H1v+48dreH9pDkfKK4kMc/kwMmOap/qGo3gAOA+4GjhPRP7UJFEZc4Lz+rTmcHkl32/e5+tQjGmW6utaenSAuhHOslUVGZ8Y0TWRqDAX36634SqM8QZPehO9rKpZwMveDsaY2kSGuRjZPYmZ6/I4ccDcKV9v4Jrnv/dRZMY0D/UmA1Vd4fxc6fVojKnDeb1bk3vwMBvzio+t21tcynNzNrFg0z57NsGYBrDnDEzAOK93a4DjRjZ9ef4WjpRXAfDdhnyfxGVMc2DJwASMtvGR9Gvfgq/X7kZVKTxSzmsLtzGuf1tSEqKYY8nAmNPm8UNnIjIQ6Fz9GFX90AsxGVOriwa24+9fZnHdS4vplhxL0ZEK/uec7vxn8Tamr9xFeWUVYS77G8eYU+VRMhCRl4CBQCZQ5axWoM5k4Bw3AchT1f41bBfgMWA8UALcoKrLPI7eBJ1bz+5GTHgof/9yPXM37mV0jyQGpMZz9oFk3lq8g+XbDzK0iz2lbMyp8rRkMFxV+57G+V8BngReq2X7OKCH8xoGPO38NKZGrhDh+rM6c0HfNjw3ZzPXDOsIwFndk3CFCHM25DO0SytW5xRQXlXFkI4tfRyxMYHB02SwUET6quraUzm5qs4Rkc517DIReM2ZTe17EUkQkXaqagPamzq1T4jiz5f0O7YcHxXG4A4JfLchnwGp8dzxn+VEhbtYeP95RIfbEFzG1MfTytXXcCeELBFZJSKrRWRVI1w/BdhRbTnHWXcSEblFRDJEJCM/3xoKzcnO7pnM6twC/ufNZaS0jKLgcDkfLM3xdVjGBARPk8GLwGRgLHAx7naAi70VVE1U9TlVTVfV9OTk5Ka8tAkQ5/Zydz0d2rkV0+8YxaAOCbw0fytVVVrPkcYYT8vP+ao6zQvXzwU6VFtOddYZc8oGpMYz/Rej6NEmlsgwFzeP6sIv31rOt+vzOL9vG1+HZ4xf87RksFxE/iMiV4vIj46+GuH604DrxG04UGDtBaYhBqTGHxvVdFz/trSLj+TFeVt8HJUx/s/TkkEUUAr8sNo6T7qWvgWcAySJSA7wABAGoKrPAJ/j7laajbtr6Y2nELsxdQpzhXDDWZ15+Iv1zMrKO1aNZIw5mZw46NdxG0WuBmaoql+NG5yenq4ZGRm+DsMEgOLSCq58ZiFb9hbz6o1DGdY10dchGeMzIrJUVdNr2lZfNVFH4D0RmSsifxaRYc6DYsYEhNiIUF6/eSipLaO56ZUlLNt+wNchGeOX6pvP4BFVPQ93Vc5K4CZgmdN+cJ2IWKuc8XtJsRG8+dNhJMVFcN2Li22CHGNqUGc1Ua0HifTF/fTwD1X1wkaPqh5WTWROx+6CI0x+cRHb95fw6JWDiIsIZf3uIkb3SKJ/SryvwzPG6+qqJjqtZOCctLeqrm9QZKfJkoE5XfsPlXHDy4tZlVNwbN3A1Him/WKUD6MypmnUlQwa8pz+DNxtCsYEjFYx4fznZ8OZuW4P7eKjyNi2n79/mcWa3AIrHZigVmcyEJHHa9sEJDR6NMY0gdiIUCamuUc96dU2jsdnbuTNRdt5+EcDfByZMb5TX2+iG4E1wNITXhlAmXdDM8b74qPCmDCwPdNW5FJcWuHrcIzxmfqSwRJgjaq+euILKGqC+IzxumuHdeRQWSWfrLCRUEzwqi8ZXAGsqGmDqnZp9GiM8YG0Dgn0adeCN7/fzul2qDAm0NX3nMF+VS1pqmCM8QUR4foRnVi7q5CPllvpwAQnmyzWGODK9A4M7dyKBz7JZOfBwwBUVilFR8p9HJkxTcOSgTG4p9P8x5WDqFTl3vdXMn3lTi6Y8h3D/zqTlTsO+jo8Y7zulJOBiLT1RiDG+FrHxGj+cFFf5mfv4463lhPmCqFlTDg3vrKEzfnFx+27dNsBLnlyHqurPbxmTCA7nZLB540ehTF+4uqhHbj3wl48NimNz381mtdvHoYAk50xjSoqq/h67R6ufeF7VuUU8PJ8myvBNA+nPByFiCxX1cFeiscjNhyFaUqrcwq45oXvKTpSQUJ0GIWHyxmQEk9KyyhmZ+WT8YfziQ5vyMP8xjSNxh6O4vkGxmNMQBmQGs+C357H3I17+WbtHiLDXfx+fB/W5Bbw+erdfJW5m8sGp/o6TGMa5JSTgao+5Y1AjPFncZFhjB/QjvED2h1bd2bnVqS2jOLDZbmWDEzAs95ExpymkBDhssEpzM/eS17hEV+HY0yDWDIwpgEuG5xClcKL87YwKyuPz1fvoqTMxjgygcdavYxpgK7JsaR1SODZOZt5ds5mwD2z2h3ndWfS0A5EhLp8HKExnrFkYEwDPXnNYDJ3FpIUG8Hhskqe+HYjD0zLZPrKnbzx02FEhllCMP7PkoExDZTaMprUltHHlkd2T+Sj5bnc9e5K7n1/FY9PSkNEfBihMfWzZGBMIxMRfjQklT2FpTzy5Xq6JMVw1wU9fR2WMXWyZGCMl9w2pitb9hbz+MyN9Gvfggv72Uguxn9ZbyJjvEREeOjSAQxIiec37686NhqqMf7IkoExXhQeGsITVw+morKKX7+9gorKKo6UV3K4rNLXoRlzHKsmMsbLOifF8NcfDeBXb68g7cGvKS6tIDIshMcnDeaHVnVk/IQlA2OawMS0FAoPl5O1p4g2cZF8s24PP39zGY9cPpArzrChLIzveT0ZiMhY4DHABbygqn87YfsNwKPA0fkGn1TVF7wdlzFNbfKIzsfe3ziqC7e+nsE9761kT+ER/uecbtb91PiUV9sMRMQFTAXGAX2Bq0Wkbw27vqOqac7LEoFp9mIjQnnphjO5ZFB7Hv0qi1tfX0qhTbFpfMjbDchDgWxV3ayqZcDbwEQvX9OYgBAR6uKxSWn8cUJfZq7P44qnF1jDsvEZbyeDFGBHteUcZ92JLheRVSLyvoh08HJMxvgNEeHmUV144bp0Nuwp5qnZ2b4OyQQpf+haOh3orKoDga+BV2vaSURuEZEMEcnIz89v0gCN8bZze7fmssEpPPvdZjadMN+yMU3B28kgF6j+l34q/20oBkBV96lqqbP4AnBGTSdS1edUNV1V05OTk70SrDG+dP/43kSEhfDAJ5mc6nS0xjSUt5PBEqCHiHQRkXBgEjCt+g4i0q7a4iXAOi/HZIxfah0Xyb0X9mJe9l4e/HStNSibJuXVrqWqWiEivwC+wt219CVVzRSRB4EMVZ0G/FJELgEqgP3ADd6MyRh/du2wTqzdWcgrC7byyYqd3DSyM2d0akX/lBbERYb5OjzTjEkgFkfT09M1IyPD12EY4zVrcgv46+frWLBpHwAhAqN7JHPVmR04v08bwkP9obnPBBoRWaqq6TVus2RgjP/aW1zK6twClmzZz0fLc9lVcIQ+7Vrw7q3DTyopHCmvZFfBEbokxfgoWuPvLBkY0wxUVimfrtrJXe+uZHSPJF64Lh1XiDA7K5/3l+Uwa30eJWWVTBjYjocu7U9CdLivQzZ+pq5kYGMTGRMgXCHCxLQUiksr+P1Ha7jz3ZXkHChh+faDJMaEMzEthYToMJ6fs5klW/fz+KTBDOua6OuwTYCwZGBMgLl2WCc25x/ixXlbaBcfycM/GsAVZ6QS5nK3I1w0oB2/fHs5N76yhNdvHsYZnVrWeJ6CknIe+mwtk0d0YmBqQhPegfFHVk1kTACqrFIWb9nP4I4JRIa5TtqeV3SEHz+zkP2Hynjn1hH0adfiuO2HSiv4yYuLWL79IANT4/nk9pE2UF4QqKuayLokGBOAXCHCiG6JNSYCcD+z8MZPhxETEcpVzy7ktx+s4pu1e8jaXUR2XhG3vJ7BqpwCLk1rz6qcAmas3dPEd2D8jVUTGdNMpbaM5j8/G84/ZmTx6apdvL1kx3Hb/3nlICY6yWDKjA2c36cNrhArHQQrSwbGNGNdkmKYes0QSisqWbr1AAdKyqmoqqJDq2iGdHS3Jfz6gp788q3lfLpqJxPTUlBVMncW8u36PDolRjMxraaxJd1tDvHR9iBcc2FtBsYEuaoqZfzjc1m/u4jocBcuEYpKKwCIDAvh+/t/cFI31dcWbuWBaZk8OLE/k4d38kXY5jRY11JjTK1CQoTnr0vnw2W5FJeWc7i8krQOLWkfH8k1Lyzi7SU7uG1Mt2P7b99XwsOfrycqzMUfP16DqnJdtVncTGCyZGCMoUOraH51fo+T1o/omshrC7by01FdCHWFoKrc/9EqXCHCZ78cxf9+uo4/fZJJRGgIV53Z0QeRm8ZivYmMMbW6cWRndhYcOdbb6I3vtzE/ex/3j+9Np8QYnrp2CKN7JPHnaWvZuveQR+csLq3gwKEyb4ZtToMlA2NMrX7Qpw0dWkXx9OxN/PyNpfzxk0xGdk/kaqcUEB4awqNXDCLUJfzm/VVUVdXcBqmqLNy0j7veWUH6Q19z0eNzqaisaspbMfWwaiJjTK1cIcL1Izrz0Gfr2JhXxL0X9uLmUV0IqdYFtW18JA9c3I973lvJozOyCBGYkbmH5LgIzuvdmpiIUF5dsJX1u4uIiwxlaJdE5mzIZ/6mfYzpaRNV+QtLBsaYOv3E6S00bkA7UhKiatzn8iEpfLF6F0/P3oQrRBjWpRV7i0t56DP3XFW928bx9ysGcsmg9ojA0P+bycfLcy0Z+BFLBsaYOkWGufjp6K517iMiTPlxGrOy8hjVI4mk2AgAcg6UsP9QGQNS4o8b7mL8gHZ8vDyXhy6tICYilMoqZd2uQpbvOMimvGLSOiRwds9kWsXYyKtNxZKBMaZRxEeHceng4x9QS20ZTWrL6JP2vWxwCm8t3s7Xa/dwYb+2XP/SYhZv3Q+42yFeWbAVETi/TxseuLhvjeeoj6ry4rwtbN9fwgMX9zv2dPXUWdkUl1Zw39jep3GXzZclA2NMk0vv1JKUhCjeX5rD9JU7WbJtPw9c3JcL+rahfXwUq3MLmLF2Ny/N28oFU+Zw65iutGkRSVlFFbkHD7NhTxG5Bw5TUaVUVFXROTGGMzq15MzOrRjSsSWuEOF3H63m/aU5ALSMDufOC3oyfeVOHv0qC3AnmtpGdA1G9gSyMcYnHv1qPVNnbQLgoUv7H2ubqC7nQAkPfJLJzPV5x9aFh4bQLTmWTq2ij03/uWFPEVl7ilCFMJeQHBvBzoIj/Pr8HmzfX8JHy3P5yyX9+PuXWfRoE8uO/SV0TY7lnVuGB9VorfYEsjHG71w+JJWX52/llrO71pgIwF3N9ML16ewpLAUg1CUkRIUR6jq5V3zRkXIyth1g0eb9ZO4s4L5xvZmYlsLhskrW7izkT59k0jI6jKnXDOHrtXt4YFomszfkc26v1l69z0BhJQNjjM8cKa+sdRjuxrRl7yHufGcFd/+wJ6N7JFNWUcX5U74jJiKUT+8Ydaw9ITuviDcXbSdEhJhwF+MHtqN3W/dcEJVVypSvs0iOjeDyM1JPmoM6ENgcyMYYc4JpK3fyy7eW0699C+4b25sNe4r4u9OeEBYilJRXEhcRyju3jqB32zj+PC2TVxduAyA2IpSfDO/EvRf2OmnY7wOHynhqdjbn9GrNyO5JTX5fdbFkYIwxJ1BVpjkNyjkHDgPuRuWHfzSA5LgIcg6UcMXTC6lU5fIhqTzz3SZ+NroLFw1sz0vztjBt5U5+NDiFR68cdCwhbNl7iBtfXszWfSUADO/aivvG9mZwR/9oqLZkYIwxtSitqOTdJTtoERXmPBT337/0N+4p4spnF3KwpJyx/dry1LVDjj19/cTMjfzz6w38OD2VS9NSWLe7iCe+3UiICFOvGULW7kKenLWJfYdKuXlkF+65sBeRYS4KDpcTFeY61vhdXFrB/322jvyiUnq0iSU2IpQlW/ezdNsBBndsye/G9z5WVdVQlgyMMeY0rc4pYNrKXO66oBdR4ce3b0yZkcXj32YfW+7dNo7nJqfTMdH9XERxaQV/+2Idb3y/nbYtIqlUJb+olNZxEdx7YS+GdUnkltcz2JhXTOfEaLbtK6GiSumWHMOgDgnMXJdH0ZFyLhrYnrO6JTIoNYGebWJrbED3hCUDY4zxAlVlXvZeBKFn21iSYyNq7Ko6P3svz8/dTFJsBF2TY/gqcw8rdxwkRNztD1OvHcLoHsmUV1ZxqLTi2GRCB0vKeOLbbD5YlsPBknIA7r2wF7ef2/204rVkYIwxfqSqyt1e8eWa3fxmbC+6JsfWub+qsm1fCSt2HKR/Sgu6t447retaMjDGGFNnMrD5DIwxxng/GYjIWBHJEpFsEfltDdsjROQdZ/siEens7ZiMMcYcz6vJQERcwFRgHNAXuFpE+p6w283AAVXtDvwLeMSbMRljjDmZt0sGQ4FsVd2sqmXA28DEE/aZCLzqvH8f+IEE08hRxhjjB7ydDFKAHdWWc5x1Ne6jqhVAAZB44olE5BYRyRCRjPz8fC+Fa4wxwSlgGpBV9TlVTVfV9ORkmyrPGGMak7eTQS7QodpyqrOuxn1EJBSIB/Z5OS5jjDHVeDsZLAF6iEgXEQkHJgHTTthnGnC98/4K4FsNxIcfjDEmgHn9oTMRGQ/8G3ABL6nq/4nIg0CGqk4TkUjgdWAwsB+YpKqb6zlnPrDtNENKAvae5rH+ojncAzSP+7B78A92D57ppKo11rMH5BPIDSEiGbU9gRcomsM9QPO4D7sH/2D30HAB04BsjDHGeywZGGOMCcpk8JyvA2gEzeEeoHnch92Df7B7aKCgazMwxhhzsmAsGRhjjDmBJQNjjDHBlQzqG07bH4lIBxGZJSJrRSRTRH7lrG8lIl+LyEbnZ0tfx1ofEXGJyHIR+dRZ7uIMW57tDGMe7usY6yIiCSLyvoisF5F1IjIi0D4HEbnT+Xe0RkTeEpFIf/8cROQlEckTkTXV1tX4exe3x517WSUiQ3wX+X/Vcg+POv+WVonIRyKSUG3b/c49ZInIhU0RY9AkAw+H0/ZHFcDdqtoXGA7c7sT9W2CmqvYAZjrL/u5XwLpqy48A/3KGLz+Aezhzf/YY8KWq9gYG4b6XgPkcRCQF+CWQrqr9cT8IOgn//xxeAcaesK623/s4oIfzugV4uolirM8rnHwPXwP9VXUgsAG4H8D5/z0J6Occ85Tz/eVVQZMM8Gw4bb+jqrtUdZnzvgj3F1AKxw/9/SpwqU8C9JCIpAIXAS84ywKch3vYcvDzexCReOBs4EUAVS1T1YME2OcAhAJRzjhg0cAu/PxzUNU5uEcnqK623/tE4DV1+x5IEJF2TRJoHWq6B1Wd4YzUDPA97rHbwH0Pb6tqqapuAbJxf395VTAlA0+G0/Zrzixwg4FFQBtV3eVs2g208VVcHvo38BugyllOBA5W+8/g759HFyAfeNmp6npBRGIIoM9BVXOBfwDbcSeBAmApgfU5HFXb7z1Q/5/fBHzhvPfJPQRTMghoIhILfAD8WlULq29zBvbz2z7CIjIByFPVpb6OpQFCgSHA06o6GDjECVVCAfA5tMT9V2cXoD0Qw8lVFwHH33/v9RGR3+OuDn7Tl3EEUzLwZDhtvyQiYbgTwZuq+qGzes/R4q/zM89X8XlgJHCJiGzFXT13Hu769wSnugL8//PIAXJUdZGz/D7u5BBIn8P5wBZVzVfVcuBD3J9NIH0OR9X2ew+o/+cicgMwAbi22mjNPrmHYEoGngyn7XecuvUXgXWqOqXapupDf18PfNLUsXlKVe9X1VRV7Yz79/6tql4LzMI9bDn4/z3sBnaISC9n1Q+AtQTQ54C7emi4iEQ7/66O3kPAfA7V1PZ7nwZc5/QqGg4UVKtO8isiMhZ31eklqlpSbdM0YJKIRIhIF9yN4Yu9HpCqBs0LGI+71X4T8Htfx+NhzKNwF4FXASuc13jcde4zgY3AN0ArX8fq4f2cA3zqvO/q/CPPBt4DInwdXz2xpwEZzmfxMdAy0D4H4C/AemAN7qHjI/z9cwDewt3GUY67hHZzbb93QHD3GtwErMbdc8pf7yEbd9vA0f/Xz1Tb//fOPWQB45oiRhuOwhhjTFBVExljjKmFJQNjjDGWDIwxxlgyMMYYgyUDY4wxWDIwxhiDJQNjABCRB0XkfOf9r0UkuoHnExE5x3mJh8d0FpFrGnJdY06XPWdgzAmcYTPSVXXvKRzjUtVK530U8AzuB7kEOBO4TVUP13OOc4B7VHXC6UVuzOmzkoFplpy/steJyPPOZC4znC/p2vZ/RUSuEJFf4h7EbZaIzHK2/VBEForIMhF5zxk0EBHZKiKPiMgy4Mqj53K+9H+OeyTKG4Gfn5gIRGSMiKxwXstFJA74GzDaWXenuCcDelREljgToNzqHHuOiMwRkc+cyU+eERH7v2waxP4BmeasBzBVVfsBB4HL6ztAVR8HdgLnquq5IpIE/AE4X1WH4B6O4q5qh+xT1SGq+vbRFU7SmQq87Lym1pCI7gFuV9U0YDRwGPcoqHNVNU1V/4V7yIICVT0Td+niZ85YNeAe3/4O3BM1dQN+5OHvxJgahda/izEBa4uqrnDeLwU6n8Y5huP+wp3vVP2HAwurbX/nxANU9bCI3ASMcVZN1ZPrY+cDU0TkTeBDVc2poWnhh8BAETk6iFw87gRXBixW1c0AIvIW7jGs3j/xBMZ4ypKBac5Kq72vBGqtJqqDAF+r6tW1bD9U00rny392bSdV1b+JyGe4Bx2cX8s8twLcoapfHbfS3bZwYnKxxj/TIFZNZMzJioA45/33wEgR6Q4gIjEi0rOhFxCRbqq6WlUfwT28eu8TrgvwFfBzZz4LRKSnM7sawFBnOPYQ4CpgXkNjMsHNSgbGnOw54EsR2em0G9wAvCUiEc72P+AeCr0hfi0i5+KeBjQT95SHVUCliKzEPYH6Y7irtpY53VPz+e9cv0uAJ4HuuOcj+KiB8ZggZ11LjQkw1gXVeINVExljjLGSgQkuIjIV97y/1T2mqi/7Ih5j/IUlA2OMMVZNZIwxxpKBMcYYLBkYY4zBkoExxhjg/wEfYi1klxfliAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    \n",
    "    for i in range(500):\n",
    "\n",
    "        # generate batch:\n",
    "        indices = np.random.choice(np.arange(len(names)), size=batch_size)\n",
    "\n",
    "        # tokenize src batch\n",
    "        batch_en = to_matrix(\n",
    "            np.array(names)[indices],\n",
    "            token_to_id=token_to_id_en,\n",
    "            max_len=MAX_LENGTH)\n",
    "\n",
    "        input_tensor = torch.from_numpy(batch_en).type(torch.int64)\n",
    "\n",
    "        # tokenize trg batch\n",
    "        batch_ru = to_matrix(\n",
    "            np.array(names_ru)[indices],\n",
    "            token_to_id=token_to_id_ru,\n",
    "            max_len=MAX_LENGTH\n",
    "        )\n",
    "\n",
    "        target_tensor = torch.from_numpy(batch_ru).type(torch.int64)\n",
    "\n",
    "        # generate preds:\n",
    "        logp_seq = model(input_tensor, target_tensor)\n",
    "        \n",
    "        # calculate loss:\n",
    "        preds = logp_seq[:-1].contiguous().view(-1, len(token_to_id_ru))\n",
    "        targets = target_tensor[1:].contiguous().view(-1)\n",
    "        \n",
    "        loss = criterion(preds, targets)\n",
    "\n",
    "        # calculate grads\n",
    "        loss.backward()\n",
    "        \n",
    "        # Let's clip the gradient\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "\n",
    "        # update grads\n",
    "        opt.step()\n",
    "\n",
    "        # zero grads\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        if (i+1) % 20 == 0:\n",
    "            loss_li.append(loss.item())\n",
    "    \n",
    "    print(f'Epoch number {epoch + 1}/{n_epoch}..')\n",
    "    plt.plot(loss_li)\n",
    "    plt.title('Cost function:')\n",
    "    plt.ylabel('- 1/m * Sum(Error_i)')\n",
    "    plt.xlabel('n_iter * step')\n",
    "    plt.show()\n",
    "    clear_output(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56280e98",
   "metadata": {},
   "source": [
    "\"Teacher forcing works by using the actual or expected output from the training dataset at the current time step y(t) as input in the next time step X(t+1), rather than the output generated by the network.\"   \n",
    "\n",
    "So, if we do not pass manualy our predicts to rnn it will use ground-truth values. More stable results can be obtained using as our predictions as well as ground-truth values with some probability ratio. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b15a6a",
   "metadata": {},
   "source": [
    "# Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94bbd4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c5e284",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# text_batch_en -> encoder ->ht\n",
    "# in loop put sos and ht -> decoder \n",
    "# decoder -> probs for tokens ~ new input & ht+1  -> decoder\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63b59cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_tokens(x, decode_di): \n",
    "    if not isinstance(x, list):\n",
    "        x = x.reshape(len(x))\n",
    "    x = ''.join([decode_di.get(c) for c in x])\n",
    "    x = re.sub('\\.', '', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a6225ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inverse dicts\n",
    "\n",
    "id_to_token_en = {j:i for i,j in token_to_id_en.items()}\n",
    "assert len(id_to_token_en) == len(token_to_id_en), 'Error with lengths'\n",
    "\n",
    "id_to_token_ru = {j:i for i,j in token_to_id_ru.items()}\n",
    "assert len(id_to_token_ru) == len(token_to_id_ru), 'Error with lengths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd11f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_one_name(model, pad_ix): \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # generate random sample: \n",
    "    indices = np.random.choice(np.arange(len(names)), size=1)\n",
    "    \n",
    "    no_eos_seq = re.sub('\\.', '', names[indices[0]])\n",
    "    print(f'Random name: {no_eos_seq}')\n",
    "    \n",
    "    # tokenize src batch\n",
    "    text_batch_en = to_matrix(\n",
    "        np.array(names)[indices],\n",
    "        token_to_id=token_to_id_en,\n",
    "        max_len=MAX_LENGTH)\n",
    "    \n",
    "    \n",
    "    text_batch_en = torch.from_numpy(text_batch_en).type(torch.int64)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        enc_hlast, enc_clast  = model.encoder(text_batch_en)\n",
    "\n",
    "        input_ = np.array([pad_ix])\n",
    "        input_ = torch.from_numpy(input_).type(torch.int64)\n",
    "        \n",
    "\n",
    "        predicted_tokens_li = [PAD_IDX]\n",
    "        \n",
    "        h_next = enc_hlast\n",
    "        c_next = enc_clast\n",
    "        \n",
    "        for i in range(1, MAX_LENGTH):\n",
    "            \n",
    "            token_preds, h_next, c_next = model.decoder(input_.unsqueeze(0), h_next, c_next)\n",
    "\n",
    "            predicted_token = token_preds.argmax(-1).item()\n",
    "            predicted_tokens_li.append(predicted_token)\n",
    "        \n",
    "            input_ = np.array([predicted_token])#.reshape(1,1)\n",
    "            input_ = torch.from_numpy(input_).type(torch.int64)\n",
    "        return predicted_tokens_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "076685a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random name:  Filide\n",
      "Translation:  Филфин \n",
      "\n",
      "\n",
      "Random name:  Starla\n",
      "Translation:  Старла \n",
      "\n",
      "\n",
      "Random name:  Valentin\n",
      "Translation:  Валентин \n",
      "\n",
      "\n",
      "Random name:  Marya\n",
      "Translation:  Маря \n",
      "\n",
      "\n",
      "Random name:  Carlina\n",
      "Translation:  Сарлина \n",
      "\n",
      "\n",
      "Random name:  Anatola\n",
      "Translation:  Анатола \n",
      "\n",
      "\n",
      "Random name:  Krystle\n",
      "Translation:  Крйстле \n",
      "\n",
      "\n",
      "Random name:  Palmer\n",
      "Translation:  Палмер \n",
      "\n",
      "\n",
      "Random name:  Jasmina\n",
      "Translation:  Жасмина \n",
      "\n",
      "\n",
      "Random name:  Tommie\n",
      "Translation:  Томмие \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10): \n",
    "    preds = translate_one_name(model, PAD_IDX)\n",
    "    decoded = decode_tokens(preds, id_to_token_ru)\n",
    "    print(f'Translation: {decoded}', '\\n'*2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work_env",
   "language": "python",
   "name": "work_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
